\section{Discussion}

While prediction error the two models seem to be negligibly different as measured by 3 losses common to pharmacokinetic research, there is a large departure in uncertainty estimates for the latent concentration in each patient.  Uncertainty estimates are salient in decision making processes, where a loss is integrated over posterior samples.  If the loss depends on the latent concentration, then (at least in this study) MAP lends credence to latent concentrations which are far lower than what is postulated by the HMC.  The extent to which this discrepancy would change decisions depends on the loss function. We see this manifest in our two example experiments for personalized dosing.  The difference in uncertainty between MAP and HMC results in small disagreement for dose size for the majority of patients, but very large disagreement for others.

While the posterior for this model is too complex to be analyzed analytically, there are good theoretical reasons to prefer HMC over MAP when analysts seek the posterior expectation of some function of parameters. These reasons are nicely summarized by Betancourt \cite{Betancourt2017-ak}, but can be distilled into the fact that expectations are computed over volumes, and in high dimensional space there exists more volume away from the mode than in a neighbourhood around it. Because the volume near the mode is so small, these regions of parameter space contribute negligibly to expectations.  Instead, regions of parameter space where the product of probability density and volume is large should contribute more to expectations, and this is where our chosen method should be focussing its computational power.  Hamiltonian Monte Carlo does exactly this.

It is important to remember that neither HMC or MAP are perfect approximations of the posterior.  Discrepancies between the two methods are expected, but not to the degree which are observed in this study.  Explanations to the observed departure in uncertainty estimates may be quickly dismissed as a problem in data sparsity; all we need is more data.  With 24 equally spaced observations per each of the 100 simulated patients, we hold that this simulation study represents an optimistic best case scenario, and that real clinical studies would collect fewer samples from fewer patients.  Priors and/or the likelihood may also be brought into question, but we reiterate that the model used was identical for both methods and had strong priors informed from existing pharmacokinetic data and exactly specified the data generating process.

\section{Conclusion}

Using Bayesian methods for personalized medicine is an understandable decision.  The high cost (monetary or otherwise) of obtaining samples from any one patient may lead to sparse data in practice.  Sparsity can be combated by incorporating prior information about the drug’s pharmacokinetics from previously conducted studies or clinical trials.

Bayesian inference for pharmacokinetic models has been done using maximum a posteriori in studies as late as 2018.  The speed and similarity to maximum likelihood makes MAP an attractive and familiar approach as compared to HMC, which can take several minutes to return samples of the posterior and can utilize quite complex mechanisms to draw from the posterior. The aforementioned studies have largely focused on prediction of latent concentrations.  As we’ve shown, MAP and HMC yield approximately equivalent predictions, with out of sample prediction error slightly favoring HMC across error metrics commonly used in population pharmacokinetic studies. 

Predictions are but one part of sequential decision making; another is uncertainty in those predictions.  We’ve shown in this study that MAP can yield much wider equal tailed posterior intervals, with 18 out of 100 patients having an MAP equal tailed posterior credible interval at least 50\% as wide or wider at their widest point than their HMC equal tailed posterior interval.  By virtue of seeking to optimize therapies for individuals, practitioners must care about precision on the patient level, and so this discrepancy between  methods of summarizing the posterior should entice practitioners to be skeptical about their preferred method.

For each of these 18 patients, MAP appears to have a lower interval estimate far below that of HMC, making it appear as if lower predicted concentrations are probable. Wider estimates of uncertainty affects sequential decision making.  When estimating expected loss under a proposed dosing regimen, integrating the loss over this uncertainty may lend credence to adverse events (like thromboembolism in the case of oral anticoagulants like apixaban) unnecessarily, making the proposed dosing regimen appear to be ineffective when in reality it could be therapeutic. 

By performing the summarization of the posterior using the same data, generated from a model fit on real pharmacokinetic observations, and using strong and informative priors, we strongly believe that this observed difference is due to the differences between methods. However, that is not to say that this is the case across all models and prior configurations.  The prior we propose is purposefully uninformative about the ratio of the elimination and absorption rate constants, so as to investigate a likely scenario in which prior information is available for some but not all of the model parameters.  Were this prior to be strongly informed, we highly suspect that the observed differences between HMC and MAP would attenuate.  This raises important questions about model specification and the degree to which practitioners can afford to be uncertain about model parameters.

We recommend that if practitioners do use MAP, that they also compare model results with HMC.  Libraries exist to perform HMC in a variety of languages including R, python, and Julia, making HMC accessible to most everyone.  Use of these libraries has the added benefit of making analysis more transparent and reproducible for the community at large.

